{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZLEBSW94qcw"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOX8i0OgViDy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHojK9Jg5H4m"
      },
      "source": [
        "**Creating the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM9q_NQ1V1Z_"
      },
      "outputs": [],
      "source": [
        "Age = [24,53,23,25,32,52,22,43,52,48]\n",
        "Salary = [40000,52000,25000,77000,48000,110000,38000,44000,27000,65000]\n",
        "CollegeDegree = ['Yes','No','No','Yes','Yes','Yes','Yes','No','No','Yes']\n",
        "\n",
        "dataset = pd.DataFrame(np.array([Age,Salary,CollegeDegree]).T,columns=['Age','Salary','CollegeDegree'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z59AfXbZWaUL"
      },
      "outputs": [],
      "source": [
        "dataset['Age'] =  dataset.Age.astype(int)\n",
        "dataset['Salary'] = dataset.Salary.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdzBLPEY5N0k"
      },
      "source": [
        "**Splitting the data into input and target features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV6uAd8Jp1za"
      },
      "outputs": [],
      "source": [
        "X = np.array(dataset.drop('CollegeDegree',axis=1))\n",
        "y = np.array(dataset['CollegeDegree'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8DrrxUg4gVx"
      },
      "source": [
        "### **Univariate Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGmvupBvV0ug"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeClasifier(object):\n",
        "  \n",
        "    def __init__(self, features, max_depth):\n",
        "        self.features = features\n",
        "        self.max_depth = max_depth\n",
        "        self.tree_depth = 0\n",
        "\n",
        "    # entropy of a given segment of data\n",
        "    def entropy(self, y): \n",
        "        cumulative_entropy = 0\n",
        "        n_y = len(y)\n",
        "        for label in set(y):   # iterating over each label in the segment\n",
        "            n_label = sum(y==label)\n",
        "            if n_label == 0 or n_y -n_label == 0:\n",
        "              entropy = 0\n",
        "            else:\n",
        "              # calculating entropy of the label\n",
        "              entropy = -(n_label *1.0/n_y)*math.log(n_label *1.0/n_y, 2) - ((n_y-n_label )*1.0/n_y)*math.log((n_y-n_label )*1.0/n_y, 2) \n",
        "              cumulative_entropy +=  n_label *1.0/n_y * entropy # weighted avg of entropies of each segment\n",
        "        return cumulative_entropy # cumulative entropy of all the labels in the segment\n",
        "\n",
        "    # entropy of the subtrees of a node\n",
        "    def entropy_of_node(self, y_pred, y):\n",
        "        if len(y_pred) == len(y): \n",
        "            n_y = len(y) \n",
        "            n_left = len(y[y_pred])\n",
        "            entropy_left = self.entropy(y[y_pred]) # entropy of the left subtree\n",
        "            n_right = n_y - n_left\n",
        "            entropy_right = self.entropy(y[~y_pred]) # entropy of the right subtree\n",
        "            # calculating total entropy of the node as a weighted average of the entropies of it's subtrees\n",
        "            total_entropy = (n_left*1.0/n_y * entropy_left) + (n_right*1.0/n_y * entropy_right) \n",
        "            return total_entropy\n",
        "        return None\n",
        "\n",
        "    # calculating information gain\n",
        "    def information_gain(self, col_ind, y):\n",
        "        col_entropy = self.entropy(y) # entropy of the column\n",
        "        min_entropy = 10\n",
        "        for value in set(col_ind): # iterating over the unique values in the given column\n",
        "            y_pred = col_ind < value # for any value in the column that is less than \"value\", y_pred is true. Else, it is false.\n",
        "            pred_entropy = self.entropy_of_node(y_pred, y) # entropy of y_pred\n",
        "            if pred_entropy <= min_entropy: # condition to check for least entropy, then calculate information gain for that\n",
        "                threshold = value\n",
        "                min_entropy = pred_entropy\n",
        "                min_info_gain = col_entropy - pred_entropy\n",
        "        return threshold, min_entropy, min_info_gain\n",
        "\n",
        "    # finding the best splitting criterion at a given node\n",
        "    def best_split(self, X, y):\n",
        "        col_ind = None\n",
        "        threshold = None\n",
        "        min_entropy = 1\n",
        "        min_info_gain = 10\n",
        "        for i, c in enumerate(X.T): # iterating over the input features in X\n",
        "            threshold_current, entropy, info_gain = self.information_gain(c, y)\n",
        "            if entropy <= min_entropy: \n",
        "                col_ind = i\n",
        "                threshold = threshold_current\n",
        "                min_entropy = entropy\n",
        "                min_info_gain = info_gain\n",
        "            elif entropy == 0: # condition to find the best threshold, loop terminating condition\n",
        "                col_ind = i\n",
        "                threshold = threshold_current\n",
        "                min_entropy = entropy\n",
        "                min_info_gain = info_gain\n",
        "                break\n",
        "        return col_ind, threshold, min_entropy, min_info_gain\n",
        "\n",
        "    def build_tree(self, X, y, depth): \n",
        "        col_ind, threshold, entropy, info_gain = self.best_split(X, y)  # calculating best split, returning the column, threshold, entropy, information gain for the best split \n",
        "        y_left, y_right = y[X[:, col_ind] < threshold], y[X[:, col_ind] >= threshold] # splitting the coumns based on the threshold of the best split\n",
        "        node = {'Attribute': self.features[col_ind],\n",
        "                'Threshold': threshold,\n",
        "                'Information gain':info_gain} # node creation\n",
        "        node['Left'] = self.fit(X[X[:, col_ind] < threshold], y_left, {}, depth+1) # constructing left subtree recursively\n",
        "        node['Right'] = self.fit(X[X[:, col_ind] >= threshold], y_right, {}, depth+1) # constructing right subtree recursively\n",
        "        self.tree_depth += 1 # incrementing the depth of the tree after adding one level \n",
        "        self.tree = node # updating the tree\n",
        "        return node\n",
        "    \n",
        "    def fit(self, X, y, node={}, depth=0):\n",
        "        if node is None or len(y) == 0 or depth >= self.max_depth: \n",
        "            return None\n",
        "        elif len(pd.value_counts(y))==1: # counts number of unique values in y\n",
        "            return {'val':y[0]}\n",
        "        else: \n",
        "            return self.build_tree(X,y,depth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOK5KA5j5WYE"
      },
      "source": [
        "**Building the decision tree for the given data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMuAI0cKWDUb",
        "outputId": "13035cde-6cf5-4c83-95d9-e4c754315d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tree:\n",
            "{'Attribute': 'Salary',\n",
            " 'Threshold': 38000,\n",
            " 'Information gain': 0.3219280948873623,\n",
            " 'Left': {'val': 'No'},\n",
            " 'Right': {'Attribute': 'Age',\n",
            "           'Threshold': 43,\n",
            "           'Information gain': 0.31127812445913283,\n",
            "           'Left': {'val': 'Yes'},\n",
            "           'Right': {'Attribute': 'Salary',\n",
            "                     'Threshold': 65000,\n",
            "                     'Information gain': 1.0,\n",
            "                     'Left': {'val': 'No'},\n",
            "                     'Right': {'val': 'Yes'}}}}\n",
            "\n",
            "Depth of the tree:  3\n"
          ]
        }
      ],
      "source": [
        "model = DecisionTreeClasifier(dataset.columns, max_depth=10)\n",
        "dt = model.fit(X, y)\n",
        "print(\"Tree:\")\n",
        "pprint(dt, sort_dicts= False)\n",
        "print()\n",
        "print(\"Depth of the tree: \", model.tree_depth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN-0ZDSy5hrs"
      },
      "source": [
        "### **Multivariate Decision Tree**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yOW7siN7irR"
      },
      "source": [
        "**Preprocessing the above data for Multivariate Decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O39CXenH3u05"
      },
      "outputs": [],
      "source": [
        "dataset['pred']=-1\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "dataset['CollegeDegree']= label_encoder.fit_transform(dataset['CollegeDegree'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KrH5GzoCtcJ"
      },
      "outputs": [],
      "source": [
        "class MultiDecisionTreeClasifier(object):\n",
        "    def __init__(self,feature_names,max_depth):\n",
        "        self.feature_names = feature_names\n",
        "        self.depth = 0\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "   # entropy of a given segment of data\n",
        "    def entropy(self,y):\n",
        "        cumulative_entropy = 0\n",
        "        n_y = len(y)\n",
        "        for label in set(y):   # iterating over each label in the segment\n",
        "            n_label = sum(y==label)\n",
        "            if n_label == 0 or n_y -n_label == 0:\n",
        "              entropy = 0\n",
        "            else:\n",
        "              # calculating entropy of the label\n",
        "              entropy = -(n_label *1.0/n_y)*math.log(n_label *1.0/n_y, 2) - ((n_y-n_label )*1.0/n_y)*math.log((n_y-n_label )*1.0/n_y, 2) \n",
        "              cumulative_entropy +=  n_label *1.0/n_y * entropy # weighted avg of entropies of each segment\n",
        "        return cumulative_entropy, n_y # cumulative entropy of all the labels in the segment, size of the segment\n",
        "    \n",
        "    # updating the alpha, beta values using the perceptron rule\n",
        "    def perceptron(self, dataset, alpha, beta):\n",
        "        for i in dataset.index:\n",
        "            x_age = dataset[\"Age\"][i]\n",
        "            x_income = dataset[\"Salary\"][i]\n",
        "            # adjusting alpha, beta values at each split\n",
        "            if alpha*x_age + beta*x_income - 1 >= 0:\n",
        "                dataset['pred'][i]=1\n",
        "                if(dataset['pred'][i] != dataset['CollegeDegree'][i]):\n",
        "                    alpha = alpha-x_age\n",
        "                    beta = beta-x_income\n",
        "            else:\n",
        "                dataset['pred'][i] = 0\n",
        "                if(dataset['pred'][i] != dataset['CollegeDegree'][i]):\n",
        "                    alpha = alpha + x_age\n",
        "                    beta = beta + x_income\n",
        "        return alpha, beta\n",
        "\n",
        "    # calculating information gain \n",
        "    def information_gain(self, dataset, y, col_entropy, col_count):\n",
        "        y_left = dataset['CollegeDegree'][dataset['pred']==0]\n",
        "        n_left = len(y_left)\n",
        "        entropy_left = self.entropy(y_left)[0] # entropy of left subtree\n",
        "        y_right = dataset['CollegeDegree'][dataset['pred']==1]\n",
        "        n_right = col_count - n_left \n",
        "        entropy_right= self.entropy(y_right)[0] # entropy of right subtree\n",
        "        # calculating total entropy of the node as a weighted average of the entropies of it's subtrees\n",
        "        total_entropy = (n_left/col_count)*entropy_left + (n_right/col_count)*entropy_right\n",
        "        return (col_entropy- total_entropy), total_entropy # returning information gain and total entropy\n",
        "    \n",
        "    def fit(self, dataset, y):\n",
        "        np.random.seed(70)\n",
        "        # randomly initializing alpha and beta values\n",
        "        alpha = np.random.rand()\n",
        "        beta = np.random.rand()\n",
        "        col_entropy = self.entropy(y)[0] # entropy of the column\n",
        "        col_count = len(y)\n",
        "        tmp = 0 # looping variable\n",
        "        while tmp < 100:\n",
        "          alpha, beta = self.perceptron(dataset, alpha, beta)\n",
        "\n",
        "          info_gain, entropy = self.information_gain(dataset, y, col_entropy, col_count)\n",
        "\n",
        "          self.alpha = alpha\n",
        "          self.beta = beta\n",
        "          self.info_gain = info_gain\n",
        "          print(\"Information gain = {an:.4f} \".format(an = info_gain), \"; Alpha = {an:.4f} \".format(an = alpha), \" ; Beta = {an:.4f} \".format(an = beta), \"; Entropy = {an:.4f} \".format(an = entropy))\n",
        "          if(entropy == 0): # condition to find the best split, loop terminating condition\n",
        "              break\n",
        "          tmp += 1      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLU_ygN17xHX"
      },
      "source": [
        "**Finding and printing alpha, beta and information gain at each split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9kdpRgrXjAS",
        "outputId": "e3941456-4dc7-4233-8e79-741b3b007c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Information gain = 0.0200  ; Alpha = -22.0725   ; Beta = 46000.8724  ; Entropy = 0.9510 \n",
            "Information gain = 0.0074  ; Alpha = -145.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.0200  ; Alpha = -168.0725   ; Beta = 46000.8724  ; Entropy = 0.9510 \n",
            "Information gain = 0.0074  ; Alpha = -291.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.0200  ; Alpha = -314.0725   ; Beta = 46000.8724  ; Entropy = 0.9510 \n",
            "Information gain = 0.0074  ; Alpha = -437.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.0200  ; Alpha = -460.0725   ; Beta = 46000.8724  ; Entropy = 0.9510 \n",
            "Information gain = 0.0074  ; Alpha = -583.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.0200  ; Alpha = -606.0725   ; Beta = 46000.8724  ; Entropy = 0.9510 \n",
            "Information gain = 0.0074  ; Alpha = -729.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.0200  ; Alpha = -752.0725   ; Beta = 46000.8724  ; Entropy = 0.9510 \n",
            "Information gain = 0.0074  ; Alpha = -875.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.0058  ; Alpha = -920.0725   ; Beta = 46000.8724  ; Entropy = 0.9651 \n",
            "Information gain = 0.0074  ; Alpha = -1043.0725   ; Beta = 0.8724  ; Entropy = 0.9635 \n",
            "Information gain = 0.9710  ; Alpha = -1043.0725   ; Beta = 0.8724  ; Entropy = 0.0000 \n"
          ]
        }
      ],
      "source": [
        "multimodel = MultiDecisionTreeClasifier(dataset.columns, max_depth=10)\n",
        "mtree = multimodel.fit(dataset, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYpLwxWA7_zN"
      },
      "source": [
        "**Plotting the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "g0QwLfuYtdjB",
        "outputId": "9d8a9d6e-7716-4756-a898-5c6fce62de8b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig2 = plt.figure()\n",
        "fig2.set_size_inches(12,8)\n",
        "ax2 = plt.axes()\n",
        "ax2.scatter(data=dataset,x='Age',y='Salary',c='CollegeDegree',cmap=plt.cm.get_cmap(\"rainbow\",3))\n",
        "xx=np.linspace(20,55,2)\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Salary\")\n",
        "ax2.plot(xx,(-1*(1/multimodel.beta) - (multimodel.alpha/multimodel.beta)*xx),color='green')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7usRKPHm0YE6"
      },
      "source": [
        "### **Advantages and Disadvantages of Multivariate Decision Trees compared to Univariate Decision Trees**\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "*   The univariate decision tree algorithm constructs the decision tree by selecting a single feature at each split, whereas the multivariate decision tree algorithm uses a linear combination of features. Unlike univariate decision trees, this produces a tree that better expresses the relationship between the features.\n",
        "*   Multivariate decision trees converge much faster than univariate decision trees for linearly separable datasets.\n",
        "*   Multivariate decision trees reduce the replication problems of univariate decision trees, increasing the accuracy of the resulting decision tree.\n",
        "\n",
        "**Disadvantages:**\n",
        "*   In multivariate decision trees, to take a linear combination of the features, we apply encoding techniques to convert nominal features into numeric values—the number of features obtained after the conversion increases, consequently increasing computational complexity.\n",
        "*   When considering multiple features during a split, it is possible that the multivariate algorithm will select a feature that contributes no or little to the information gain."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
